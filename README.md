# Deep Learning Challenge

## Description

The nonprofit foundation Alphabet Soup wants a tool that can help it select the applicants for funding with the best chance of success in their ventures. With your knowledge of machine learning and neural networks, you’ll use the features in the provided dataset to create a binary classifier that can predict whether applicants will be successful if funded by Alphabet Soup. From Alphabet Soup’s business team, you have received a CSV containing more than 34,000 organizations that have received funding from Alphabet Soup over the years. 

## Getting Started

#### The instructions for this Challenge are divided into the following subsections:

* Step 1: Preprocess the Data
* Step 2: Compile, Train, and Evaluate the Model
* Step 3: Optimize the Model
* Step 4: Write a Report on the Neural Network Model
* Step 5: Copy Files Into Your Repository

## Setup

* numpy 1.21.6
* pandas 1.0.5
* scikit-learn 1.0.2
* imbalanced-learn 0.11.0

## Dependencies

* import numpy as np
* import pandas as pd
* from pathlib import Path
* from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report
* from imblearn.over_sampling import RandomOverSampler

## Grading

* Split the Data into Training and Testing Sets (30 points)
* Create a Logistic Regression Model (30 points)
* Write a Credit Risk Analysis Report (20 points)
* Coding Conventions and Formatting (10 points)
* Code Comments (10 points)

## Overview of the Analysis

The purpose of this analysis is to create a model that can accurately predict healthy loans and high-risk loans. 

The dataset was from over 75,000 loans. The information included the loan size, interest rate, borrower income, debt-to-income ratio, number of accounts, derogatory marks, total debt and loan status.

Firstly, the y variable was set as the loan status column and the features were the all other columns.

Then the data was split into training and testing sets. I then created a logistic regression model, fit the model, made predictions using the test data and evaluated the performance.

Lastly, I repeated the above steps with resampled training data.

## Results


### Logistic Regression Model:

|            | precision | recall | f1-score | support |
|-----------:|:---------:|:------:|:--------:|:-------:|
| 0          |   1.00    |  0.99  |    1.00  |    18765|
| 1          |   0.85    |  0.91  |   0.88   |    619  |
|    accuracy|           |        |     0.99 |    19384|
|   macro avg|       0.92|    0.95|      0.94|    19384|
|weighted avg|       0.99|    0.99|      0.99|    19384|



### Logistic Regression Model with Resampled Training Data:

|            | precision | recall | f1-score | support |
|-----------:|:---------:|:------:|:--------:|:-------:|
| 0          |   1.00    |  0.99  |    1.00  |    18765|
| 1          |   0.84    |  0.99  |   0.91   |    619  |
|    accuracy|           |        |     0.99 |    19384|
|   macro avg|       0.92|    0.99|      0.95|    19384|
|weighted avg|       0.99|    0.99|      0.99|    19384|

## Summary

Given the nature of the data (credit risk), we want our models to put an empasis on low false negatives. This means that the higher the recall for high-risk loans (1), the better our model is.

This is why I would recommend the Logistic Regression Model with Resampled Training Data. It has a recall score of 0.99 for high-risk loans (1) compared to 0.91 with the other model. 

## Authors

Danik Lafrance https://github.com/daniklafrance

## References

Data for this dataset was generated by edX Boot Camps LLC, and is intended for educational purposes only.